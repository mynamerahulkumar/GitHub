Optimization

Welcome to the optimization's  of the hyper-parameters tuning specialization. There are many different optimization algorithms exist that can be used to get the minimal cost. Similarly, there are many different paths down this hill to the lowest point.

I have done following optimization to get the minimal cost:

- Understand the intuition between Adam and RMS prop

- Recognize the importance of mini-batch gradient descent

- Learn the effects of momentum on the overall performance of your model